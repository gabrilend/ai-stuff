#!/usr/bin/env luajit

-- Multi-threaded HTML page generation using effil
-- Generates similarity and difference pages in parallel for better performance

-- {{{ Early help check (before any requires)
-- Check for --help early, before setting up package paths
for i = 1, #arg do
    if arg[i] == "--help" or arg[i] == "-h" then
        print([[
Usage: generate-html-parallel [DIR] [OPTIONS]

Options:
  --test           Generate only first 10 pages (for testing)
  --similar-only   Generate only similarity pages
  --different-only Generate only difference pages
  --incremental    Skip poems that already have HTML files
  --threads=N      Number of parallel threads (default: 8)
  -h, --help       Show this help message

Examples:
  generate-html-parallel                      # Default: 8 threads, all pages
  generate-html-parallel . 4                  # 4 threads
  generate-html-parallel . --incremental      # Skip existing files
  generate-html-parallel . --similar-only     # Only similarity pages
]])
        os.exit(0)
    end
end
-- }}}

-- {{{ local function setup_dir_path
local function setup_dir_path(provided_dir)
    if provided_dir then
        return provided_dir
    end
    return "/mnt/mtwo/programming/ai-stuff/neocities-modernization"
end
-- }}}

-- {{{ Parse directory from arguments (before package.path setup)
local function find_dir_arg(args)
    for i = 1, #args do
        local a = args[i]
        -- Skip flags
        if a:sub(1, 1) ~= "-" and a:match("^%d+$") == nil then
            return a
        end
    end
    return nil
end

local DIR = setup_dir_path(find_dir_arg(arg))
-- }}}

-- Add effil library path
package.cpath = "/home/ritz/programming/ai-stuff/libs/lua/effil-jit/build/?.so;" .. package.cpath
package.path = DIR .. "/libs/?.lua;" .. DIR .. "/src/?.lua;" .. package.path

local effil = require("effil")
local utils = require("utils")
local dkjson = require("dkjson")

-- {{{ local function relative_path
local function relative_path(absolute_path)
    if absolute_path:sub(1, #DIR) == DIR then
        local rel = absolute_path:sub(#DIR + 1)
        if rel:sub(1, 1) == "/" then rel = rel:sub(2) end
        return "./" .. rel
    end
    return absolute_path
end
-- }}}

-- {{{ Argument parsing
-- Parse command line arguments for more flexible option handling
local function parse_args(args)
    local opts = {
        dir = nil,
        threads = 8,
        test = false,
        similar_only = false,
        different_only = false,
        incremental = false,  -- Skip existing files
        help = false
    }

    local i = 1
    while args and i <= #args do
        local a = args[i]
        if a == "--test" then
            opts.test = true
        elseif a == "--similar-only" then
            opts.similar_only = true
        elseif a == "--different-only" then
            opts.different_only = true
        elseif a == "--incremental" or a == "-i" then
            opts.incremental = true
        elseif a == "--help" or a == "-h" then
            opts.help = true
        elseif a:match("^--threads=") then
            opts.threads = tonumber(a:match("^--threads=(%d+)")) or 8
        elseif a:match("^%d+$") then
            opts.threads = tonumber(a)
        elseif a:sub(1, 1) ~= "-" then
            opts.dir = a
        end
        i = i + 1
    end

    return opts
end

local OPTS = parse_args(arg)
-- Note: --help is handled early (before requires) at top of script
-- }}}

-- Configuration (from parsed arguments)
local NUM_THREADS = OPTS.threads
local TEST_MODE = OPTS.test
local SIMILARITY_ONLY = OPTS.similar_only
local DIFFERENCE_ONLY = OPTS.different_only
local INCREMENTAL_MODE = OPTS.incremental
local MAX_TEST_PAGES = 10
local DIVERSITY_LIMIT = 0  -- 0 = all poems, or set to limit diversity sequence length
local USE_CACHE = true  -- Use pre-computed diversity sequences if available

-- Update DIR if provided in args
if OPTS.dir then
    DIR = OPTS.dir
end

-- Color configuration (shared)
local COLOR_CONFIG = {
    red = "#dc3c3c",
    blue = "#3c78dc",
    green = "#3cb45a",
    purple = "#8c3cc8",
    orange = "#e68c3c",
    yellow = "#c8b428",
    gray = "#787878"
}

-- {{{ Worker function for similarity page generation
-- Note: This function must not capture any upvalues - all data passed as parameters
local function similarity_worker(poem_id, poem_content, poem_category, similarities_for_poem,
                                  all_poems_array, poem_colors_table, max_poem_id, output_dir)
    -- CRITICAL FIX: Copy effil.tables to local Lua tables at worker start
    -- This avoids catastrophic IPC overhead (17B accesses ‚Üí single O(n) copy)
    -- See issue 8-002 "Bug 2: Catastrophic effil.table Access Overhead"

    local local_poems_array = {}
    for i = 1, #all_poems_array do
        local_poems_array[i] = all_poems_array[i]
    end

    local local_similarities = {}
    for k, v in pairs(similarities_for_poem) do
        local_similarities[k] = v
    end

    local local_colors = {}
    for k, v in pairs(poem_colors_table) do
        local_colors[k] = v
    end

    -- Generate similarity ranking
    local ranked_poems = {}

    -- Add starting poem first
    table.insert(ranked_poems, {
        id = poem_id,
        content = poem_content,
        category = poem_category,
        similarity = 1.0
    })

    -- Add other poems sorted by similarity (using local copies of effil.tables)
    local other_poems = {}
    for i = 1, #local_poems_array, 3 do
        local other_id = local_poems_array[i]
        local other_content = local_poems_array[i + 1]
        local other_category = local_poems_array[i + 2]

        if other_id ~= poem_id then
            local sim_score = local_similarities[tostring(other_id)] or 0
            table.insert(other_poems, {
                id = other_id,
                content = other_content,
                category = other_category,
                similarity = sim_score
            })
        end
    end

    table.sort(other_poems, function(a, b)
        return a.similarity > b.similarity
    end)

    for _, p in ipairs(other_poems) do
        table.insert(ranked_poems, p)
    end

    -- Generate HTML content
    local content_parts = {}
    for _, poem_info in ipairs(ranked_poems) do
        local pid = poem_info.id

        -- Calculate progress
        local progress_pct = (pid / max_poem_id) * 100
        local progress_chars = math.floor((progress_pct / 100) * 80)
        local remaining_chars = 80 - progress_chars

        -- Get color (using local copy of effil.table)
        local color_name = local_colors[tostring(pid)] or "gray"
        local hex_color = ({
            red = "#dc3c3c", blue = "#3c78dc", green = "#3cb45a",
            purple = "#8c3cc8", orange = "#e68c3c", yellow = "#c8b428", gray = "#787878"
        })[color_name] or "#787878"

        -- Generate progress bar
        local progress_section = string.rep("‚ïê", progress_chars)
        local remaining_section = string.rep("‚îÄ", remaining_chars)
        local progress_bar = string.format('<font color="%s"><b>%s</b></font>%s',
            hex_color, progress_section, remaining_section)

        -- Format poem entry
        table.insert(content_parts, string.format(" -> file: %s/%s.txt\n", poem_info.category or "unknown", pid))
        table.insert(content_parts, string.format('<div aria-label="eighty dashes. %s.">%s</div>\n', color_name, progress_bar))
        table.insert(content_parts, (poem_info.content or "") .. "\n")
        table.insert(content_parts, string.format('<div aria-label="eighty dashes. %s.">%s</div>\n\n', color_name, progress_bar))
    end

    local html_content = table.concat(content_parts)

    -- Generate HTML
    local html = string.format([[<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Poems sorted by similarity to: Poem %d</title>
</head>
<body>
<center>
<h1>Poetry Collection</h1>
<p>All poems sorted by similarity to: Poem %d</p>
<pre>
%s
</pre>
</center>
</body>
</html>]], poem_id, poem_id, html_content)

    -- Write file
    local filename = string.format("%s/similar/%03d.html", output_dir, poem_id)
    local f = io.open(filename, "w")
    if f then
        f:write(html)
        f:close()
        return true
    end
    return false
end
-- }}}

-- {{{ Worker function for difference page generation (centroid-based diversity)
-- Note: This function must not capture any upvalues - all data passed as parameters
local function diversity_worker(poem_id, poem_content, poem_category, starting_embedding_flat,
                                 all_poems_array, all_embeddings_flat, embedding_dim,
                                 poem_colors_table, max_poem_id, output_dir, diversity_limit)
    -- CRITICAL FIX: Copy effil.tables to local Lua tables at worker start
    -- This is especially important for diversity_worker which has O(n¬≤) access patterns
    -- Without this fix: ~17 BILLION IPC calls per sequence (~5 hours)
    -- With this fix: single O(n) copy, then fast local access
    -- See issue 8-002 "Bug 2: Catastrophic effil.table Access Overhead"

    local local_poems_array = {}
    for i = 1, #all_poems_array do
        local_poems_array[i] = all_poems_array[i]
    end

    local local_embeddings_flat = {}
    for i = 1, #all_embeddings_flat do
        local_embeddings_flat[i] = all_embeddings_flat[i]
    end

    local local_starting_embedding = {}
    for i = 1, #starting_embedding_flat do
        local_starting_embedding[i] = starting_embedding_flat[i]
    end

    local local_colors = {}
    for k, v in pairs(poem_colors_table) do
        local_colors[k] = v
    end

    -- Helper: cosine distance between two embeddings (passed as flat arrays with offset)
    local function cosine_distance(emb1, emb2)
        local dot_product = 0
        local norm1 = 0
        local norm2 = 0

        for i = 1, #emb1 do
            dot_product = dot_product + (emb1[i] * emb2[i])
            norm1 = norm1 + (emb1[i] * emb1[i])
            norm2 = norm2 + (emb2[i] * emb2[i])
        end

        norm1 = math.sqrt(norm1)
        norm2 = math.sqrt(norm2)

        if norm1 == 0 or norm2 == 0 then
            return 1.0
        end

        return 1.0 - (dot_product / (norm1 * norm2))
    end

    -- Helper: calculate centroid of a list of embeddings
    local function calculate_centroid(embeddings_list)
        if #embeddings_list == 0 then return nil end

        local dim = #embeddings_list[1]
        local centroid = {}
        for i = 1, dim do centroid[i] = 0 end

        for _, emb in ipairs(embeddings_list) do
            for i = 1, dim do
                centroid[i] = centroid[i] + emb[i]
            end
        end

        for i = 1, dim do
            centroid[i] = centroid[i] / #embeddings_list
        end

        return centroid
    end

    -- Build starting embedding as table (using local copy)
    local starting_embedding = {}
    for i = 1, embedding_dim do
        starting_embedding[i] = local_starting_embedding[i]
    end

    -- Build list of other poems with embeddings (using local copies)
    local remaining_poems = {}
    local num_poems = #local_poems_array / 3

    for i = 1, num_poems do
        local idx = (i - 1) * 3 + 1
        local other_id = local_poems_array[idx]
        local other_content = local_poems_array[idx + 1]
        local other_category = local_poems_array[idx + 2]

        if other_id ~= poem_id then
            -- Extract embedding for this poem (using local copy)
            local emb_start = (i - 1) * embedding_dim + 1
            local embedding = {}
            for j = 1, embedding_dim do
                embedding[j] = local_embeddings_flat[emb_start + j - 1]
            end

            table.insert(remaining_poems, {
                id = other_id,
                content = other_content,
                category = other_category,
                embedding = embedding
            })
        end
    end

    -- Generate diversity sequence using centroid-based selection
    local diversity_sequence = {{
        id = poem_id,
        content = poem_content,
        category = poem_category
    }}
    local selected_embeddings = {starting_embedding}

    -- Limit diversity sequence if specified
    local max_sequence = diversity_limit > 0 and diversity_limit or (#remaining_poems + 1)

    while #remaining_poems > 0 and #diversity_sequence < max_sequence do
        local centroid = calculate_centroid(selected_embeddings)
        if not centroid then break end

        -- Find poem with maximum distance from centroid
        local max_dist = -1
        local max_idx = -1

        for i, poem_info in ipairs(remaining_poems) do
            local dist = cosine_distance(centroid, poem_info.embedding)
            if dist > max_dist then
                max_dist = dist
                max_idx = i
            end
        end

        if max_idx > 0 then
            local selected = remaining_poems[max_idx]
            table.insert(diversity_sequence, {
                id = selected.id,
                content = selected.content,
                category = selected.category
            })
            table.insert(selected_embeddings, selected.embedding)
            table.remove(remaining_poems, max_idx)
        else
            break
        end
    end

    -- Generate HTML content
    local content_parts = {}
    for _, poem_info in ipairs(diversity_sequence) do
        local pid = poem_info.id

        -- Calculate progress
        local progress_pct = (pid / max_poem_id) * 100
        local progress_chars = math.floor((progress_pct / 100) * 80)
        local remaining_chars = 80 - progress_chars

        -- Get color (using local copy of effil.table)
        local color_name = local_colors[tostring(pid)] or "gray"
        local hex_color = ({
            red = "#dc3c3c", blue = "#3c78dc", green = "#3cb45a",
            purple = "#8c3cc8", orange = "#e68c3c", yellow = "#c8b428", gray = "#787878"
        })[color_name] or "#787878"

        -- Generate progress bar
        local progress_section = string.rep("‚ïê", progress_chars)
        local remaining_section = string.rep("‚îÄ", remaining_chars)
        local progress_bar = string.format('<font color="%s"><b>%s</b></font>%s',
            hex_color, progress_section, remaining_section)

        -- Format poem entry
        table.insert(content_parts, string.format(" -> file: %s/%s.txt\n", poem_info.category or "unknown", pid))
        table.insert(content_parts, string.format('<div aria-label="eighty dashes. %s.">%s</div>\n', color_name, progress_bar))
        table.insert(content_parts, (poem_info.content or "") .. "\n")
        table.insert(content_parts, string.format('<div aria-label="eighty dashes. %s.">%s</div>\n\n', color_name, progress_bar))
    end

    local html_content = table.concat(content_parts)

    -- Generate HTML
    local html = string.format([[<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Poems sorted by difference from: Poem %d</title>
</head>
<body>
<center>
<h1>Poetry Collection</h1>
<p>All poems sorted by difference from: Poem %d</p>
<pre>
%s
</pre>
</center>
</body>
</html>]], poem_id, poem_id, html_content)

    -- Write file
    local filename = string.format("%s/different/%03d.html", output_dir, poem_id)
    local f = io.open(filename, "w")
    if f then
        f:write(html)
        f:close()
        return true
    end
    return false
end
-- }}}

-- {{{ Worker function for cached difference page generation (uses pre-computed sequences)
-- Much faster than on-the-fly computation - just looks up poem data and generates HTML
local function cached_diversity_worker(poem_id, diversity_sequence, all_poems_lookup,
                                        poem_colors_table, max_poem_id, output_dir)
    -- CRITICAL FIX: Copy effil.tables to local Lua tables at worker start
    -- See issue 8-002 "Bug 2: Catastrophic effil.table Access Overhead"

    local local_sequence = {}
    for i = 1, #diversity_sequence do
        local_sequence[i] = diversity_sequence[i]
    end

    local local_poems_lookup = {}
    for k, v in pairs(all_poems_lookup) do
        local_poems_lookup[k] = v
    end

    local local_colors = {}
    for k, v in pairs(poem_colors_table) do
        local_colors[k] = v
    end

    -- diversity_sequence is already ordered list of poem IDs
    -- all_poems_lookup maps poem_id -> {content, category}

    -- Generate HTML content
    local content_parts = {}
    for _, pid in ipairs(local_sequence) do
        local poem_data = local_poems_lookup[tostring(pid)]
        if poem_data then
            -- Calculate progress
            local progress_pct = (pid / max_poem_id) * 100
            local progress_chars = math.floor((progress_pct / 100) * 80)
            local remaining_chars = 80 - progress_chars

            -- Get color (using local copy of effil.table)
            local color_name = local_colors[tostring(pid)] or "gray"
            local hex_color = ({
                red = "#dc3c3c", blue = "#3c78dc", green = "#3cb45a",
                purple = "#8c3cc8", orange = "#e68c3c", yellow = "#c8b428", gray = "#787878"
            })[color_name] or "#787878"

            -- Generate progress bar
            local progress_section = string.rep("‚ïê", progress_chars)
            local remaining_section = string.rep("‚îÄ", remaining_chars)
            local progress_bar = string.format('<font color="%s"><b>%s</b></font>%s',
                hex_color, progress_section, remaining_section)

            -- Format poem entry
            table.insert(content_parts, string.format(" -> file: %s/%s.txt\n", poem_data.category or "unknown", pid))
            table.insert(content_parts, string.format('<div aria-label="eighty dashes. %s.">%s</div>\n', color_name, progress_bar))
            table.insert(content_parts, (poem_data.content or "") .. "\n")
            table.insert(content_parts, string.format('<div aria-label="eighty dashes. %s.">%s</div>\n\n', color_name, progress_bar))
        end
    end

    local html_content = table.concat(content_parts)

    -- Generate HTML
    local html = string.format([[<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Poems sorted by difference from: Poem %d</title>
</head>
<body>
<center>
<h1>Poetry Collection</h1>
<p>All poems sorted by difference from: Poem %d</p>
<pre>
%s
</pre>
</center>
</body>
</html>]], poem_id, poem_id, html_content)

    -- Write file
    local filename = string.format("%s/different/%03d.html", output_dir, poem_id)
    local f = io.open(filename, "w")
    if f then
        f:write(html)
        f:close()
        return true
    end
    return false
end
-- }}}

-- {{{ Main execution
print("=" .. string.rep("=", 60))
print("Multi-threaded HTML Generation")
print("=" .. string.rep("=", 60))
print(string.format("Project directory: %s", relative_path(DIR)))
print(string.format("Thread count: %d", NUM_THREADS))
local mode_desc = TEST_MODE and "test (first " .. MAX_TEST_PAGES .. " pages)" or
                  SIMILARITY_ONLY and "similarity only" or
                  DIFFERENCE_ONLY and "difference only" or "full"
print(string.format("Mode: %s", mode_desc))

-- Load data files
print("\nüîÑ Loading data files...")
local poems_file = DIR .. "/assets/poems.json"
local similarities_dir = DIR .. "/assets/embeddings/EmbeddingGemma_latest/similarities/"
local poem_colors_file = DIR .. "/assets/embeddings/EmbeddingGemma_latest/poem_colors.json"
local embeddings_file = DIR .. "/assets/embeddings/EmbeddingGemma_latest/embeddings.json"
local diversity_cache_file = DIR .. "/assets/embeddings/EmbeddingGemma_latest/diversity_cache.json"

local poems_data = utils.read_json_file(poems_file)
local poem_colors_data = utils.read_json_file(poem_colors_file)
local embeddings_data = nil
local diversity_cache = nil

-- {{{ local function load_individual_similarity_files
-- Loads similarity data from individual poem_X.json files in similarities_dir
-- Returns a dictionary matching the expected format: {poem_id: {other_id: score, ...}, ...}
-- This replaces the monolithic similarity_matrix.json with per-poem files
local function load_individual_similarity_files(sim_dir)
    local similarities = {}
    local loaded_count = 0

    -- Find all similarity files
    local handle = io.popen("find '" .. sim_dir .. "' -name 'poem_*.json' 2>/dev/null")
    if not handle then
        return nil, 0
    end

    local files = {}
    for filepath in handle:lines() do
        table.insert(files, filepath)
    end
    handle:close()

    if #files == 0 then
        return nil, 0
    end

    print(string.format("   Loading %d individual similarity files...", #files))

    -- Load each file and convert to expected format
    for i, filepath in ipairs(files) do
        local sim_data = utils.read_json_file(filepath)
        if sim_data and sim_data.metadata and sim_data.similarities then
            local poem_id = sim_data.metadata.poem_id
            if poem_id then
                -- Convert array format to dictionary: {other_id: score, ...}
                local poem_sims = {}
                for _, entry in ipairs(sim_data.similarities) do
                    if entry.id then
                        poem_sims[tostring(entry.id)] = entry.similarity
                    end
                end
                similarities[tostring(poem_id)] = poem_sims
                loaded_count = loaded_count + 1
            end
        end

        -- Progress update every 500 files
        if i % 500 == 0 then
            print(string.format("      Loaded %d/%d files...", i, #files))
        end
    end

    return similarities, loaded_count
end
-- }}}

-- Load similarities from individual files (replaces similarity_matrix.json)
local similarity_data = nil
local similarity_count = 0
if not DIFFERENCE_ONLY then
    similarity_data, similarity_count = load_individual_similarity_files(similarities_dir)
    if similarity_data then
        print(string.format("   ‚úÖ Loaded similarities for %d poems from individual files", similarity_count))
    end
end

-- Check for diversity cache first (much faster than computing on-the-fly)
if not SIMILARITY_ONLY and USE_CACHE then
    diversity_cache = utils.read_json_file(diversity_cache_file)
    if diversity_cache then
        print("   ‚úÖ Diversity cache found - using pre-computed sequences")
    end
end

-- Only load embeddings if generating difference pages AND no cache
if not SIMILARITY_ONLY and not diversity_cache then
    print("   Loading embeddings (62MB, may take a moment)...")
    print("   Note: Run scripts/precompute-diversity-sequences for faster generation")
    embeddings_data = utils.read_json_file(embeddings_file)
end

if not poems_data then
    print("‚ùå Error: Could not load poems.json")
    os.exit(1)
end

if not similarity_data and not DIFFERENCE_ONLY then
    print("‚ùå Error: Could not load similarity files from " .. similarities_dir)
    print("   Run: lua src/similarity-engine-parallel.lua -I  (to generate similarity files)")
    os.exit(1)
end

if not embeddings_data and not diversity_cache and not SIMILARITY_ONLY then
    print("‚ùå Error: Could not load embeddings.json or diversity_cache.json")
    print("   Run: scripts/precompute-diversity-sequences")
    os.exit(1)
end

-- Validate that all poems with content have valid embeddings
-- Load embeddings for validation if not already loaded
local validation_embeddings = embeddings_data
if not validation_embeddings then
    validation_embeddings = utils.read_json_file(embeddings_file)
end

if validation_embeddings and validation_embeddings.embeddings then
    local missing_embeddings = {}
    local invalid_dimensions = {}
    local random_embeddings = 0

    for i, poem in ipairs(poems_data.poems) do
        if poem.id and poem.content and poem.content ~= "" then
            local emb_entry = validation_embeddings.embeddings[i]
            if not emb_entry or not emb_entry.embedding then
                table.insert(missing_embeddings, poem.id)
            elseif type(emb_entry.embedding) ~= "table" or #emb_entry.embedding ~= 768 then
                table.insert(invalid_dimensions, poem.id)
            elseif emb_entry.is_random then
                random_embeddings = random_embeddings + 1
            end
        end
    end

    if #missing_embeddings > 0 or #invalid_dimensions > 0 then
        print("\n‚ùå EMBEDDING VALIDATION FAILED")
        print("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        if #missing_embeddings > 0 then
            print(string.format("   Missing embeddings: %d poems with content have no embedding", #missing_embeddings))
            print("   First 10 IDs: " .. table.concat({unpack(missing_embeddings, 1, 10)}, ", "))
        end
        if #invalid_dimensions > 0 then
            print(string.format("   Invalid dimensions: %d poems have wrong embedding size", #invalid_dimensions))
            print("   First 10 IDs: " .. table.concat({unpack(invalid_dimensions, 1, 10)}, ", "))
        end
        print("")
        print("   Please regenerate embeddings before generating HTML:")
        print("   lua src/similarity-engine.lua -I  (option 1)")
        print("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        os.exit(1)
    end

    if random_embeddings > 0 then
        print(string.format("   ‚ÑπÔ∏è  %d empty poems have random embeddings (expected)", random_embeddings))
    end
end

local similarities = similarity_data and (similarity_data.similarities or similarity_data) or {}
local embedding_dim = embeddings_data and embeddings_data.metadata and embeddings_data.metadata.embedding_dimension or 768
print("‚úÖ Data files loaded")
print(string.format("   üìÑ Poems: %d", #poems_data.poems))
if diversity_cache then
    local cache_count = 0
    for _ in pairs(diversity_cache.sequences or {}) do cache_count = cache_count + 1 end
    print(string.format("   üì¶ Diversity cache: %d sequences", cache_count))
elseif embeddings_data then
    print(string.format("   üßÆ Embeddings: %d (dim=%d)", #embeddings_data.embeddings, embedding_dim))
end

-- Build flat array of poems for worker (id, content, category triplets)
-- Also build embeddings lookup for diversity generation
local all_poems_array = {}
local all_embeddings_flat = {}
local poem_lookup = {}
local poem_index_lookup = {}  -- poem_id -> index in arrays
local valid_poem_ids = {}
local max_poem_id = 0

for i, poem in ipairs(poems_data.poems) do
    if poem.id then
        table.insert(all_poems_array, poem.id)
        table.insert(all_poems_array, poem.content or "")
        table.insert(all_poems_array, poem.category or "unknown")

        -- Store embedding as flat values if available
        if embeddings_data and embeddings_data.embeddings[i] and embeddings_data.embeddings[i].embedding then
            for _, val in ipairs(embeddings_data.embeddings[i].embedding) do
                table.insert(all_embeddings_flat, val)
            end
        else
            -- Pad with zeros if no embedding
            for _ = 1, embedding_dim do
                table.insert(all_embeddings_flat, 0)
            end
        end

        poem_lookup[poem.id] = poem
        poem_index_lookup[poem.id] = i
        table.insert(valid_poem_ids, poem.id)
        if poem.id > max_poem_id then
            max_poem_id = poem.id
        end
    end
end

-- Build poem colors lookup (just color names)
local poem_colors_lookup = {}
if poem_colors_data and poem_colors_data.poem_colors then
    for id, data in pairs(poem_colors_data.poem_colors) do
        poem_colors_lookup[tostring(id)] = data.color or "gray"
    end
end

-- Build poem content lookup for cached diversity worker (id -> {content, category})
local poem_content_lookup = {}
for _, poem in ipairs(poems_data.poems) do
    if poem.id then
        poem_content_lookup[tostring(poem.id)] = {
            content = poem.content or "",
            category = poem.category or "unknown"
        }
    end
end

-- Sort IDs for consistent ordering
table.sort(valid_poem_ids)

-- Limit in test mode
if TEST_MODE then
    local limited_ids = {}
    for i = 1, math.min(MAX_TEST_PAGES, #valid_poem_ids) do
        table.insert(limited_ids, valid_poem_ids[i])
    end
    valid_poem_ids = limited_ids
end

-- {{{ Incremental mode: skip poems that already have HTML files
-- Filter out poem IDs that have existing output files
local function file_exists(path)
    local f = io.open(path, "r")
    if f then f:close() return true end
    return false
end

local skipped_similar = 0
local skipped_different = 0
local original_count = #valid_poem_ids

-- Track which poem IDs need similarity vs difference pages (for incremental mode)
local sim_needed_set = {}
local diff_needed_set = {}

if INCREMENTAL_MODE then
    local output_dir = DIR .. "/output"

    -- Check each poem for existing files
    local sim_needed_count = 0
    local diff_needed_count = 0

    for _, poem_id in ipairs(valid_poem_ids) do
        local sim_file = string.format("%s/similar/%03d.html", output_dir, poem_id)
        local diff_file = string.format("%s/different/%03d.html", output_dir, poem_id)

        if not file_exists(sim_file) then
            sim_needed_set[poem_id] = true
            sim_needed_count = sim_needed_count + 1
        else
            skipped_similar = skipped_similar + 1
        end

        if not file_exists(diff_file) then
            diff_needed_set[poem_id] = true
            diff_needed_count = diff_needed_count + 1
        else
            skipped_different = skipped_different + 1
        end
    end

    -- Filter to poems needing at least one type of page
    local filtered_ids = {}
    for _, poem_id in ipairs(valid_poem_ids) do
        local needs_sim = (not DIFFERENCE_ONLY) and sim_needed_set[poem_id]
        local needs_diff = (not SIMILARITY_ONLY) and diff_needed_set[poem_id]
        if needs_sim or needs_diff then
            table.insert(filtered_ids, poem_id)
        end
    end

    valid_poem_ids = filtered_ids

    if skipped_similar > 0 or skipped_different > 0 then
        print(string.format("   ‚è≠Ô∏è  Incremental mode: skipping existing files"))
        if not DIFFERENCE_ONLY then
            print(string.format("      Similar pages: %d exist, %d to generate", skipped_similar, sim_needed_count))
        end
        if not SIMILARITY_ONLY then
            print(string.format("      Difference pages: %d exist, %d to generate", skipped_different, diff_needed_count))
        end
    end

    -- If nothing to do, exit early
    if #valid_poem_ids == 0 then
        print("\n‚úÖ All pages already exist, nothing to generate")
        os.exit(0)
    end
else
    -- Non-incremental mode: mark all poems as needing generation
    for _, poem_id in ipairs(valid_poem_ids) do
        sim_needed_set[poem_id] = true
        diff_needed_set[poem_id] = true
    end
end
-- }}}

print(string.format("   üî¢ Pages to generate: %d", #valid_poem_ids))

-- Create output directories
local output_dir = DIR .. "/output"
os.execute("mkdir -p " .. output_dir .. "/similar")
os.execute("mkdir -p " .. output_dir .. "/different")

-- Convert data to effil-shareable format
print("\nüì¶ Converting data for parallel processing...")
local shared_poems_array = effil.table(all_poems_array)
local shared_colors = effil.table(poem_colors_lookup)
local shared_embeddings = nil
if embeddings_data then
    print("   Converting embeddings to shared format...")
    shared_embeddings = effil.table(all_embeddings_flat)
    print(string.format("   ‚úÖ Embeddings converted (%d values)", #all_embeddings_flat))
end

-- Generate similarity pages in parallel (unless --different-only)
-- Note: sim_failed removed - we now fail-fast on any error
local sim_completed = 0
local sim_elapsed = 0

if not DIFFERENCE_ONLY then
    print("\nüöÄ Generating similarity pages...")
    local start_time = os.time()

    local threads = {}

    -- Process in batches
    local batch_start = 1
    while batch_start <= #valid_poem_ids do
        local batch_end = math.min(batch_start + NUM_THREADS - 1, #valid_poem_ids)

        -- Start threads for this batch (skip poems that don't need similarity pages in incremental mode)
        local batch_threads = {}
        local batch_poem_ids = {}
        local thread_idx = 0

        for i = batch_start, batch_end do
            local poem_id = valid_poem_ids[i]

            -- In incremental mode, skip poems that already have similarity pages
            if not sim_needed_set[poem_id] then
                -- Already exists, skip (counted in skipped_similar earlier)
            else
                local poem = poem_lookup[poem_id]
                local poem_sims = similarities[tostring(poem_id)] or {}

                -- Convert similarities to effil table
                local shared_sims = effil.table(poem_sims)

                thread_idx = thread_idx + 1
                batch_poem_ids[thread_idx] = poem_id
                batch_threads[thread_idx] = effil.thread(similarity_worker)(
                    poem_id,
                    poem.content or "",
                    poem.category or "unknown",
                    shared_sims,
                    shared_poems_array,
                    shared_colors,
                    max_poem_id,
                    output_dir
                )
            end
        end

        -- Wait for batch to complete (FAIL-FAST: any failure stops generation)
        for i = 1, thread_idx do
            local status = batch_threads[i]:wait()
            -- effil doesn't return function values directly, check file existence instead
            local poem_id = batch_poem_ids[i]
            local filename = string.format("%s/similar/%03d.html", output_dir, poem_id)
            local f = io.open(filename, "r")
            if f then
                f:close()
                sim_completed = sim_completed + 1
            else
                -- FAIL-FAST: Stop immediately on any page generation failure
                print(string.format("\n‚ùå SIMILARITY PAGE GENERATION FAILED"))
                print(string.format("   Poem ID: %d", poem_id))
                print(string.format("   Expected file: %s", filename))
                print(string.format("   Completed before failure: %d/%d", sim_completed, #valid_poem_ids))
                print("")
                print("   Remedy: Check similarity data for this poem:")
                print(string.format("   - Similarity file: %s/assets/embeddings/EmbeddingGemma_latest/similarities/poem_%d.json", DIR, poem_id))
                print("   - Regenerate similarity data: lua src/similarity-engine-parallel.lua -I")
                os.exit(1)
            end
        end

        -- Progress update
        local elapsed = os.time() - start_time
        local rate = sim_completed / math.max(elapsed, 1)
        print(string.format("   Similarity: %d/%d completed (%.1f pages/sec)",
            sim_completed, #valid_poem_ids, rate))

        threads = {}
        batch_start = batch_end + 1
    end

    sim_elapsed = os.time() - start_time
    print(string.format("\n‚úÖ Similarity pages: %d in %d seconds (%.1f pages/sec)",
        sim_completed, sim_elapsed, sim_completed / math.max(sim_elapsed, 1)))
else
    print("\n‚è≠Ô∏è  Skipping similarity pages (--different-only)")
end

-- Generate difference pages in parallel (unless --similar-only)
-- Note: diff_failed removed - we now fail-fast on any error
local diff_completed = 0
local diff_elapsed = 0

if not SIMILARITY_ONLY and (diversity_cache or shared_embeddings) then
    local using_cache = diversity_cache ~= nil

    if using_cache then
        print("\nüöÄ Generating difference pages (using cached sequences)...")
        -- Convert poem content lookup to effil-shareable format
        local shared_poem_content = effil.table(poem_content_lookup)
    else
        print("\nüöÄ Generating difference pages (O(n¬≤) diversity algorithm)...")
        print("   Note: This is slower than similarity due to centroid calculations")
        print("   Tip: Run scripts/precompute-diversity-sequences for faster generation")
    end

    local start_time = os.time()

    -- Process in batches
    local batch_start = 1
    while batch_start <= #valid_poem_ids do
        local batch_end = math.min(batch_start + NUM_THREADS - 1, #valid_poem_ids)

        -- Start threads for this batch (skip poems that don't need difference pages in incremental mode)
        local batch_threads = {}
        local batch_poem_ids = {}
        local thread_idx = 0

        for i = batch_start, batch_end do
            local poem_id = valid_poem_ids[i]

            -- In incremental mode, skip poems that already have difference pages
            if not diff_needed_set[poem_id] then
                -- Already exists, skip (counted in skipped_different earlier)
            elseif using_cache then
                -- Use cached sequence (fast path)
                local cached_sequence = diversity_cache.sequences[tostring(poem_id)]
                if cached_sequence then
                    local shared_sequence = effil.table(cached_sequence)
                    local shared_poem_content = effil.table(poem_content_lookup)

                    thread_idx = thread_idx + 1
                    batch_poem_ids[thread_idx] = poem_id
                    batch_threads[thread_idx] = effil.thread(cached_diversity_worker)(
                        poem_id,
                        shared_sequence,
                        shared_poem_content,
                        shared_colors,
                        max_poem_id,
                        output_dir
                    )
                end
            else
                -- Compute on-the-fly (slow path)
                local poem = poem_lookup[poem_id]
                local poem_index = poem_index_lookup[poem_id]

                -- Extract embedding for starting poem
                local emb_start = (poem_index - 1) * embedding_dim + 1
                local starting_embedding = {}
                for j = 1, embedding_dim do
                    starting_embedding[j] = all_embeddings_flat[emb_start + j - 1]
                end
                local shared_starting_emb = effil.table(starting_embedding)

                thread_idx = thread_idx + 1
                batch_poem_ids[thread_idx] = poem_id
                batch_threads[thread_idx] = effil.thread(diversity_worker)(
                    poem_id,
                    poem.content or "",
                    poem.category or "unknown",
                    shared_starting_emb,
                    shared_poems_array,
                    shared_embeddings,
                    embedding_dim,
                    shared_colors,
                    max_poem_id,
                    output_dir,
                    DIVERSITY_LIMIT
                )
            end
        end

        -- Wait for batch to complete (FAIL-FAST: any failure stops generation)
        for i = 1, thread_idx do
            if batch_threads[i] then
                local status = batch_threads[i]:wait()
            end
            -- Check file existence to verify success
            local poem_id = batch_poem_ids[i]
            local filename = string.format("%s/different/%03d.html", output_dir, poem_id)
            local f = io.open(filename, "r")
            if f then
                f:close()
                diff_completed = diff_completed + 1
            else
                -- FAIL-FAST: Stop immediately on any page generation failure
                print(string.format("\n‚ùå DIFFERENCE PAGE GENERATION FAILED"))
                print(string.format("   Poem ID: %d", poem_id))
                print(string.format("   Expected file: %s", filename))
                print(string.format("   Completed before failure: %d/%d", diff_completed, #valid_poem_ids))
                print("")
                print("   Remedy: Check diversity data for this poem:")
                print(string.format("   - Diversity cache: %s/assets/embeddings/EmbeddingGemma_latest/diversity_cache.json", DIR))
                print("   - Regenerate diversity data: scripts/precompute-diversity-sequences")
                os.exit(1)
            end
        end

        -- Progress update
        local elapsed = os.time() - start_time
        local rate = diff_completed / math.max(elapsed, 1)
        print(string.format("   Difference: %d/%d completed (%.1f pages/sec)",
            diff_completed, #valid_poem_ids, rate))

        batch_start = batch_end + 1
    end

    diff_elapsed = os.time() - start_time
    print(string.format("\n‚úÖ Difference pages: %d in %d seconds (%.1f pages/sec)",
        diff_completed, diff_elapsed, diff_completed / math.max(diff_elapsed, 1)))
else
    if SIMILARITY_ONLY then
        print("\n‚è≠Ô∏è  Skipping difference pages (--similar-only)")
    else
        print("\n‚ö†Ô∏è  Skipping difference pages (no cache or embeddings)")
        print("   Run: scripts/precompute-diversity-sequences")
    end
end

-- Summary (FAIL-FAST: if we reach here, all pages generated successfully)
print("\n" .. string.rep("=", 61))
print("Generation Summary")
print(string.rep("=", 61))
if not DIFFERENCE_ONLY then
    print(string.format("   Similarity pages: %d completed", sim_completed))
end
if not SIMILARITY_ONLY then
    print(string.format("   Difference pages: %d completed", diff_completed))
end
local total_elapsed = sim_elapsed + diff_elapsed
print(string.format("   Total time: %d seconds", total_elapsed))

print("\nüìñ Output directory: " .. relative_path(output_dir))
if not DIFFERENCE_ONLY then
    print("   Similar: firefox " .. relative_path(output_dir) .. "/similar/001.html")
end
if not SIMILARITY_ONLY then
    print("   Different: firefox " .. relative_path(output_dir) .. "/different/001.html")
end
-- }}}
