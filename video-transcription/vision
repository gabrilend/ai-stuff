video-transcription is a library dedicated to solving the problem of video file
size limitations and enable infinite expression through text-based descriptions
of pre-existing files. Each second, the description of the scene is added to a
file which is then used as the context for that particular video frame that
could be image generated by an image generator which can take a series of
concatenated files of text as input context.

the interval is configurable but should be considered the "frame rate" of the
program.

it should allow for user-inserted files (simply a file in a different directory
with the filename of the timestamp the user would like to append to / overwrite)
which allows for precise customization should the need arise.

it should allow for user-inserted images (simply a picture file in a different
directory with the filename of the timestamp the user would like to overwrite /
overlay-as-context) which allows for precise customization should the need arise

so, to clarify, one file for each interval. The files are both text and images
which are used as context when the video generation library is used. But first,
they should be analyzed, which is where the speech-to-text and image recognition
libraries come into play. the goal is to create a template that can generate
new visual works without using the old work as input, rather simply deriving
them. In this way they can be better applied to different mediums or projects.
